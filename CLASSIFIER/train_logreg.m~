function [model,vld_acc,tst_acc] = train_logreg(conf, trn_dat,trn_lab, vld_dat,vld_lab, tst_dat,tst_lab)

if nargin<2
trn_dat = get_data_from_file(conf.trn_dat_file,conf.row_dat);
if nargin<3
trn_lab = get_data_from_file(conf.trn_lab_file,conf.row_dat);
if nargin<4
vld_dat = get_data_from_file(conf.vld_dat_file,conf.row_dat);
if nargin<5
vld_lab = get_data_from_file(conf.vld_lab_file,conf.row_dat);
if nargin<6
tst_dat = get_data_from_file(conf.tst_dat_file,conf.row_dat);
if nargin<7
tst_lab = get_data_from_file(conf.tst_lab_file,conf.row_dat);
end
end
end
end
end
end

obj_fnc = conf.objective_function;
% Select cost function
objective_funcs;

% Select error function for update/back-prob
logreg_error_funcs;

% Get dimentionalities
[visNum,SZ] = size(trn_dat);
lNum = numel(unique(trn_lab));

% Batch 
if conf.sNum == 0, conf.sNum = SZ; end
if conf.bNum == 0, conf.bNum = ceil(SZ/conf.sNum); end

% Initialize params
model.W     = min([0.001 1/visNum])*(2*rand(visNum,lNum)-1);
model.labB  = zeros(lNum,1);

DW = zeros(size(model.W));
DB = zeros(size(model.labB));


STOP = 0;
e=0;
lr = conf.params(1);
while ~STOP
    e = e+1;
    inx = randperm(SZ);
    trn_acc = 0;
    cost_vl = 0;
    for b=1:conf.bNum
        iii = inx((b-1)*conf.sNum+1:min(b*conf.sNum,SZ));
        X = trn_dat(:,iii);        
        L = trn_lab(iii)+1;
        
        sNum = size(X,2);
        probs = get_probs(X,model);                                      
        
        % Target label
        err = error_fnc(probs,discrete2softmax(L,lNum));
        
        diff = X*err'/sNum;
        % Update
        DW = lr*(diff-conf.params(4)*model.W) + conf.params(3)*DW;
        model.W = model.W + DW;
        
        DB =  lr*mean(err,2) + conf.params(3)*DB;
        model.labB = model.labB + DB;
        
        % Get error
        trn_acc = trn_acc + sum(sum(L==max(get_probs(X,model))))/sNum; 
        % Get cost     
        cost_vl = cost_vl + cost_fnc(probs,L);
    end
    trn_acc = trn_acc/conf.bNum;
    vld_acc = sum(sum(vld_lab==max(get_probs(vld_dat,model))-1))/numel(vld_lab); 
    tst_acc = sum(sum(tst_lab==max(get_probs(tst_dat,model))-1))/numel(tst_lab); 
    
    % Learning rate decay + early stopping
    
    
    % Print out
    fprintf('[Epoch %d] Cost=%.5f|trn_acc=%.5f|vld_acc=%.5f|tst_acc=%.5f\n',e,cost_vl,trn_acc,vld_acc,tst_acc);
    
end
end
function probs = get_probs(X,model)
    I = bsxfun(@plus,model.W'*X,model.labB);
    I = exp(bsxfun(@minus,I,max(I)));% exponents of normalized input
    probs = bsxfun(@rdivide,I,sum(I));        
end

